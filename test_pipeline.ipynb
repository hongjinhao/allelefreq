{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba52ea5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199a5531",
   "metadata": {},
   "source": [
    "## Load and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9780410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data\n",
    "df_raw = pd.read_csv(\"afnd.tsv\", sep=\"\\t\")\n",
    "print(f\"Raw data shape: {df_raw.shape}\")\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2523b4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data using clean_data function\n",
    "df_clean = clean_data(df_raw, class1_only=True, remove_g_groups=True, verbose=True)\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87f9bcc",
   "metadata": {},
   "source": [
    "## Test Resolution Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d366b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add resolution column and check distribution\n",
    "df_clean['resolution'] = df_clean['allele'].apply(get_allele_resolution)\n",
    "print(\"Resolution distribution:\")\n",
    "print(df_clean['resolution'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3eef239",
   "metadata": {},
   "source": [
    "## Test Individual Collapse Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b392b1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test collapse_8digit_to_6digit\n",
    "df_collapsed_6d, changes_8to6 = collapse_8digit_to_6digit(df_clean, verbose=True)\n",
    "print(f\"\\nChanges log shape: {changes_8to6.shape}\")\n",
    "if len(changes_8to6) > 0:\n",
    "    display(changes_8to6.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22804100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test collapse_6digit_to_4digit\n",
    "df_collapsed_4d, changes_6to4 = collapse_6digit_to_4digit(df_collapsed_6d, verbose=True)\n",
    "print(f\"\\nChanges log shape: {changes_6to4.shape}\")\n",
    "if len(changes_6to4) > 0:\n",
    "    display(changes_6to4.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5b4c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check resolution distribution after collapsing\n",
    "print(\"Resolution distribution after collapsing:\")\n",
    "print(df_collapsed_4d['resolution'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc7ad0c",
   "metadata": {},
   "source": [
    "## Test 2-digit Inconsistency Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcbb669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test find_2digit_larger_than_children\n",
    "larger_parents = find_2digit_larger_than_children(df_collapsed_4d, threshold=0.001, verbose=True)\n",
    "print(f\"\\nFound {len(larger_parents)} cases where 2-digit freq > sum of 4-digit children\")\n",
    "if len(larger_parents) > 0:\n",
    "    display(larger_parents.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447a7d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test remove_inconsistent_2digit_studies\n",
    "df_consistent = remove_inconsistent_2digit_studies(df_collapsed_4d, max_total_diff=0.005, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e4ab0d",
   "metadata": {},
   "source": [
    "## Test Frequency Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c457cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 2-digit entries first\n",
    "df_4digit_only = df_consistent[df_consistent['resolution'] == '4-digit']\n",
    "print(f\"Shape after removing 2-digit entries: {df_4digit_only.shape}\")\n",
    "\n",
    "# Test validate_frequency_sums\n",
    "valid_df, invalid_df = validate_frequency_sums(df_4digit_only, threshold=0.1, verbose=True)\n",
    "if len(invalid_df) > 0:\n",
    "    print(\"\\nInvalid combinations:\")\n",
    "    display(invalid_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0924ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test remove_invalid_freq_combinations\n",
    "df_validated = remove_invalid_freq_combinations(df_4digit_only, threshold=0.1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd4d29b",
   "metadata": {},
   "source": [
    "## Test Complete Pipeline (collapse_to_4digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca87295f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Starting collapse_to_4digit pipeline\n",
      "================================================================================\n",
      "Input shape: (96960, 5)\n",
      "Input studies: 832\n",
      "\n",
      "Resolution distribution before collapse:\n",
      "{'4-digit': 68780, '2-digit': 22010, '6-digit': 5688, '8-digit': 482}\n",
      "\n",
      "--- Step 1: Collapse 8-digit to 6-digit ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collapsing 8-digit to 6-digit: 100%|██████████| 832/832 [00:12<00:00, 68.92it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsed 8-digit to 6-digit: (96960, 6) -> (96798, 6)\n",
      "  Updates: 93\n",
      "  Created: 320\n",
      "\n",
      "--- Step 2: Collapse 6-digit to 4-digit ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collapsing 6-digit to 4-digit: 100%|██████████| 832/832 [02:01<00:00,  6.83it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsed 6-digit to 4-digit: (96798, 6) -> (94851, 6)\n",
      "  Updates: 482\n",
      "  Created: 4061\n",
      "\n",
      "--- Step 3: Remove inconsistent 2-digit studies ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding 2-digit inconsistencies: 100%|██████████| 832/832 [01:15<00:00, 10.97it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 26 studies with total_diff > 0.005\n",
      "  Shape: (94851, 6) -> (90488, 6)\n",
      "  Studies: 832 -> 806\n",
      "\n",
      "--- Step 4: Remove 2-digit entries ---\n",
      "Removed 21077 2-digit entries\n",
      "  Shape: 90488 -> 69411\n",
      "\n",
      "--- Step 5: Validate frequency sums ---\n",
      "Removed 232 invalid (population, gene) combinations\n",
      "  Shape: (69411, 6) -> (62925, 6)\n",
      "  Studies: 525 -> 381\n",
      "\n",
      "--- Step 6: Filter by sample size >= 100 ---\n",
      "Studies: 381 -> 250\n",
      "\n",
      "================================================================================\n",
      "Pipeline complete!\n",
      "================================================================================\n",
      "Final shape: (47421, 6)\n",
      "Final studies: 250\n",
      "Resolution distribution: {'4-digit': 47421}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Reload utils to ensure we have the latest version\n",
    "from importlib import reload\n",
    "import utils\n",
    "reload(utils)\n",
    "from utils import *\n",
    "\n",
    "# Load fresh data\n",
    "df_raw = pd.read_csv(\"afnd.tsv\", sep=\"\\t\")\n",
    "df_clean = clean_data(df_raw, verbose=False)\n",
    "\n",
    "# Run the complete pipeline\n",
    "df_final = collapse_to_4digit(\n",
    "    df_clean,\n",
    "    remove_inconsistent_studies=True,\n",
    "    max_2digit_diff=0.005,\n",
    "    freq_sum_threshold=0.1,\n",
    "    min_sample_size=100,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5b86ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Final Verification\n",
      "================================================================================\n",
      "\n",
      "Resolution check: ['4-digit']\n",
      "✓ All entries are 4-digit\n",
      "\n",
      "Frequency sum range: [0.9040, 1.0970]\n",
      "✓ All frequency sums within [0.9, 1.1]\n",
      "\n",
      "Sample size range: [100, 3456066]\n",
      "✓ All sample sizes >= 100\n",
      "\n",
      "✓ All validations passed!\n",
      "Final dataset: 47421 rows, 250 studies\n"
     ]
    }
   ],
   "source": [
    "# Verify the final result\n",
    "print(\"=\" * 80)\n",
    "print(\"Final Verification\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check all entries are 4-digit\n",
    "print(f\"\\nResolution check: {df_final['resolution'].unique()}\")\n",
    "assert (df_final['resolution'] == '4-digit').all(), \"Not all entries are 4-digit!\"\n",
    "print(\"✓ All entries are 4-digit\")\n",
    "\n",
    "# Check frequency sums\n",
    "freq_sums = df_final.groupby(['population', 'gene'])['alleles_over_2n'].sum()\n",
    "print(f\"\\nFrequency sum range: [{freq_sums.min():.4f}, {freq_sums.max():.4f}]\")\n",
    "assert freq_sums.min() >= 0.9 and freq_sums.max() <= 1.1, \"Frequency sums out of range!\"\n",
    "print(\"✓ All frequency sums within [0.9, 1.1]\")\n",
    "\n",
    "# Check sample size\n",
    "print(f\"\\nSample size range: [{df_final['n'].min()}, {df_final['n'].max()}]\")\n",
    "assert df_final['n'].min() >= 100, \"Sample sizes below 100!\"\n",
    "print(\"✓ All sample sizes >= 100\")\n",
    "\n",
    "print(f\"\\n✓ All validations passed!\")\n",
    "print(f\"Final dataset: {df_final.shape[0]} rows, {df_final['population'].nunique()} studies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71218ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene</th>\n",
       "      <th>allele</th>\n",
       "      <th>population</th>\n",
       "      <th>alleles_over_2n</th>\n",
       "      <th>n</th>\n",
       "      <th>resolution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12485</th>\n",
       "      <td>B</td>\n",
       "      <td>B*07:02</td>\n",
       "      <td>Armenia combined Regions</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>100</td>\n",
       "      <td>4-digit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12486</th>\n",
       "      <td>B</td>\n",
       "      <td>B*07:02</td>\n",
       "      <td>Australia Cape York Peninsula Aborigine</td>\n",
       "      <td>0.0450</td>\n",
       "      <td>103</td>\n",
       "      <td>4-digit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12487</th>\n",
       "      <td>B</td>\n",
       "      <td>B*07:02</td>\n",
       "      <td>Australia New South Wales Caucasian</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>134</td>\n",
       "      <td>4-digit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12488</th>\n",
       "      <td>B</td>\n",
       "      <td>B*07:02</td>\n",
       "      <td>Australia Yuendumu Aborigine</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>191</td>\n",
       "      <td>4-digit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12489</th>\n",
       "      <td>B</td>\n",
       "      <td>B*07:02</td>\n",
       "      <td>Austria</td>\n",
       "      <td>0.1290</td>\n",
       "      <td>200</td>\n",
       "      <td>4-digit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12493</th>\n",
       "      <td>B</td>\n",
       "      <td>B*07:02</td>\n",
       "      <td>Brazil  Puyanawa</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>150</td>\n",
       "      <td>4-digit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12498</th>\n",
       "      <td>B</td>\n",
       "      <td>B*07:02</td>\n",
       "      <td>Cameroon Beti</td>\n",
       "      <td>0.0860</td>\n",
       "      <td>174</td>\n",
       "      <td>4-digit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12503</th>\n",
       "      <td>B</td>\n",
       "      <td>B*07:02</td>\n",
       "      <td>China Beijing Shijiazhuang Tianjian Han</td>\n",
       "      <td>0.0340</td>\n",
       "      <td>618</td>\n",
       "      <td>4-digit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12504</th>\n",
       "      <td>B</td>\n",
       "      <td>B*07:02</td>\n",
       "      <td>China Canton Han</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>264</td>\n",
       "      <td>4-digit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12505</th>\n",
       "      <td>B</td>\n",
       "      <td>B*07:02</td>\n",
       "      <td>China Guangzhou</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>102</td>\n",
       "      <td>4-digit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12509</th>\n",
       "      <td>B</td>\n",
       "      <td>B*07:02</td>\n",
       "      <td>China Hubei Han</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>3732</td>\n",
       "      <td>4-digit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12510</th>\n",
       "      <td>B</td>\n",
       "      <td>B*07:02</td>\n",
       "      <td>China Jiangsu Han</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>3238</td>\n",
       "      <td>4-digit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12511</th>\n",
       "      <td>B</td>\n",
       "      <td>B*07:02</td>\n",
       "      <td>China Jiangsu Province Han</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>334</td>\n",
       "      <td>4-digit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12512</th>\n",
       "      <td>B</td>\n",
       "      <td>B*07:02</td>\n",
       "      <td>China North Han</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>105</td>\n",
       "      <td>4-digit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12514</th>\n",
       "      <td>B</td>\n",
       "      <td>B*07:02</td>\n",
       "      <td>China Yunnan Hani</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>150</td>\n",
       "      <td>4-digit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12515</th>\n",
       "      <td>B</td>\n",
       "      <td>B*07:02</td>\n",
       "      <td>Colombia BogotÃ¡ Cord Blood</td>\n",
       "      <td>0.0499</td>\n",
       "      <td>1463</td>\n",
       "      <td>4-digit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12517</th>\n",
       "      <td>B</td>\n",
       "      <td>B*07:02</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>0.0970</td>\n",
       "      <td>150</td>\n",
       "      <td>4-digit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12518</th>\n",
       "      <td>B</td>\n",
       "      <td>B*07:02</td>\n",
       "      <td>Croatia pop 4</td>\n",
       "      <td>0.0681</td>\n",
       "      <td>4000</td>\n",
       "      <td>4-digit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12522</th>\n",
       "      <td>B</td>\n",
       "      <td>B*07:02</td>\n",
       "      <td>Czech Republic NMDR</td>\n",
       "      <td>0.1190</td>\n",
       "      <td>5099</td>\n",
       "      <td>4-digit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12523</th>\n",
       "      <td>B</td>\n",
       "      <td>B*07:02</td>\n",
       "      <td>England North West</td>\n",
       "      <td>0.1530</td>\n",
       "      <td>298</td>\n",
       "      <td>4-digit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gene   allele                               population  alleles_over_2n  \\\n",
       "12485    B  B*07:02                 Armenia combined Regions           0.0300   \n",
       "12486    B  B*07:02  Australia Cape York Peninsula Aborigine           0.0450   \n",
       "12487    B  B*07:02      Australia New South Wales Caucasian           0.1200   \n",
       "12488    B  B*07:02             Australia Yuendumu Aborigine           0.0000   \n",
       "12489    B  B*07:02                                  Austria           0.1290   \n",
       "12493    B  B*07:02                         Brazil  Puyanawa           0.0600   \n",
       "12498    B  B*07:02                            Cameroon Beti           0.0860   \n",
       "12503    B  B*07:02  China Beijing Shijiazhuang Tianjian Han           0.0340   \n",
       "12504    B  B*07:02                         China Canton Han           0.0080   \n",
       "12505    B  B*07:02                          China Guangzhou           0.0000   \n",
       "12509    B  B*07:02                          China Hubei Han           0.0162   \n",
       "12510    B  B*07:02                        China Jiangsu Han           0.0215   \n",
       "12511    B  B*07:02               China Jiangsu Province Han           0.0193   \n",
       "12512    B  B*07:02                          China North Han           0.0190   \n",
       "12514    B  B*07:02                        China Yunnan Hani           0.0100   \n",
       "12515    B  B*07:02              Colombia BogotÃ¡ Cord Blood           0.0499   \n",
       "12517    B  B*07:02                                  Croatia           0.0970   \n",
       "12518    B  B*07:02                            Croatia pop 4           0.0681   \n",
       "12522    B  B*07:02                      Czech Republic NMDR           0.1190   \n",
       "12523    B  B*07:02                       England North West           0.1530   \n",
       "\n",
       "          n resolution  \n",
       "12485   100    4-digit  \n",
       "12486   103    4-digit  \n",
       "12487   134    4-digit  \n",
       "12488   191    4-digit  \n",
       "12489   200    4-digit  \n",
       "12493   150    4-digit  \n",
       "12498   174    4-digit  \n",
       "12503   618    4-digit  \n",
       "12504   264    4-digit  \n",
       "12505   102    4-digit  \n",
       "12509  3732    4-digit  \n",
       "12510  3238    4-digit  \n",
       "12511   334    4-digit  \n",
       "12512   105    4-digit  \n",
       "12514   150    4-digit  \n",
       "12515  1463    4-digit  \n",
       "12517   150    4-digit  \n",
       "12518  4000    4-digit  \n",
       "12522  5099    4-digit  \n",
       "12523   298    4-digit  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the final data\n",
    "df_final.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80fa1e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(\"cleaned_data2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d9cc861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned_data.csv shape: (47421, 7)\n",
      "cleaned_data2.csv shape: (47421, 7)\n",
      "\n",
      "Same shape: True\n",
      "Same columns: True\n",
      "\n",
      "Dataframes are identical: True\n"
     ]
    }
   ],
   "source": [
    "# Compare cleaned_data.csv and cleaned_data2.csv\n",
    "df1 = pd.read_csv(\"cleaned_data.csv\")\n",
    "df2 = pd.read_csv(\"cleaned_data2.csv\")\n",
    "\n",
    "print(f\"cleaned_data.csv shape: {df1.shape}\")\n",
    "print(f\"cleaned_data2.csv shape: {df2.shape}\")\n",
    "print(f\"\\nSame shape: {df1.shape == df2.shape}\")\n",
    "print(f\"Same columns: {list(df1.columns) == list(df2.columns)}\")\n",
    "\n",
    "# Check if identical\n",
    "if df1.shape == df2.shape and list(df1.columns) == list(df2.columns):\n",
    "    print(f\"\\nDataframes are identical: {df1.equals(df2)}\")\n",
    "    \n",
    "    # If not identical, show differences\n",
    "    if not df1.equals(df2):\n",
    "        diff = df1.compare(df2)\n",
    "        print(f\"\\nNumber of cell differences: {len(diff)}\")\n",
    "        if len(diff) > 0:\n",
    "            display(diff.head(20))\n",
    "else:\n",
    "    # Find rows unique to each using merge\n",
    "    merged = df1.merge(df2, indicator=True, how='outer')\n",
    "    print(\"\\nRow comparison:\")\n",
    "    print(merged['_merge'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvName",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
